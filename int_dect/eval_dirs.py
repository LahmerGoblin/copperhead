#!/usr/bin/python3
# -*- coding: utf-8 -*-

import json
import sys
import codecs
import re

from IPython import embed

conn_in = 'conn_conv.json'
fileout ='filenames_trainset.json'
dirout ='dirames_trainset.json'

if len(sys.argv)>1:
    if sys.argv[1] == 'test':
        conn_in = 'conn_conv_test.json'
        fileout ='filenames_testset.json'
        dirout ='dirames_testset.json'

# load separated connections generated by process_json.py
connections = json.load(codecs.open(conn_in,'r'))
files_per_conn = {}
dirs_per_conn = {}
for connection in connections:
    #source_port = connection[0]['_source']['layers']['tcp.port'][0]
    files = []
    dirs = []
    pwd = None
    for i,ftp_message in enumerate(connection) :
        dstport = ftp_message['_source']['layers']['tcp.port'][0]
        srcport  = ftp_message['_source']['layers']['tcp.port'][1]
        request_command = None
        request_argument = None
        response_argument = None
        response_command = None
        response_response_command = None

        try:
            request_command = ftp_message['_source']['layers']['ftp.request.command'][0]
        except KeyError:
            pass

        try:
            request_argument = ftp_message['_source']['layers']['ftp.request.arg']
        except KeyError:
            pass

        try:
            # Response in next message
            response_command = connection[i+1]['_source']['layers']['ftp.response.code'][0]
        except KeyError:
            pass
        except IndexError:
            print('Request unanswered')

        try:
            # Response in next message
            response_response_command = connection[i+2]['_source']['layers']['ftp.response.code'][0]
        except KeyError:
            pass
        except IndexError:
            print('Request unanswered')

        try:
            response_argument = connection[i+1]['_source']['layers']['ftp.response.arg']
        except KeyError:
            pass
        except IndexError:
            if request_command is not None:
                print('no response to request: ' + request_command)
            else:
                print('IndexError on connection ' + dstport)


        # Possibilities, where directories of files could be named
        
        # change to a directory via CWD
        # 250 Requested file action okay, completed.
        if request_command == 'CWD' and response_command == '250':
            # Test, whether cwd argument was pointing towards a file
            # if so, append to files.
            # filename23.zip
            matcher = re.compile('^.*\.[a-zA-Z]{1,4}$')
            match = matcher.match(request_argument[0].split('/')[-1])
            if match is not None  :
                if pwd is not None:
                    files.append(pwd + request_argument[0])
                else:
                    files.append(request_argument[0])
                pwd = request_argument[0:-(len(request_argument[0].split('/')[-1])+1)]
                if len(pwd) == 0:
                    pwd = '/'

            # set pwd to new directory
            elif pwd is None or request_argument[0][0] == '/': 
                pwd = request_argument[0]
            else:
                pwd += '/' + request_argument[0]
            dirs.append(pwd)

            
        # change a directory via CWUP
        if request_command == 'CDUP' and response_command == '250':
            if request_argument is not None:
                if pwd is not None:
                    # subtract last directory
                    pwd = pwd[-(len(pwd.split('/')[-1])+1)]
                dirs.append(pwd)

        # TODO: Include correct succeed response
        if request_command == 'PWD' and response_command == '257':
            print('PWD')
            if request_argument is not None:
                pwd = request_argument[0]
                dirs.append(pwd)
        # MKD - make directory - which should succeed.
        if request_command == 'MKD' and response_command != '550':
            print('MKD')
            if request_argument is not None:
                if pwd is not None:
                    if type(request_argument) == list:
                        for s in request_argument:
                            dirs.append(pwd + s)
                    else:
                        dirs.append(request_argument)
                else:
                    dirs.extend(request_argument)
        
        # SNMT
        if request_command ==  'LIST' and response_command == '150': 
            print('LIST')
            if request_argument is not None:
                if pwd is not None :
                    dirs.extend(pwd + request_argument[0])
                else:
                    dirs.extend(request_argument)

        # File Commands

        # RETR
        # 226 too strong since transfer must be completed
        if request_command == 'RETR' and response_command == '150':# and response_response_command=='226':
            if type(request_argument) == list:
                for s in request_argument:
                    if pwd is not None:
                        files.append(pwd + s)
                    else:
                        files.append(s)
            else: 
                if pwd is not None:
                    files.append(pwd + request_argument)
                else:
                    files.append(request_argument)
        #if request_command == 'RETR' and response_command == '150' and response_response_command!='226':
        #    embed()
    files_per_conn[dstport] = files    
    dirs_per_conn[dstport] = dirs    

# get rid of doubled slashes like 'home//arne'
for f in files_per_conn.keys():
    for s in files_per_conn[f]:
        s.replace('//','/')
for d in dirs_per_conn.keys():
    for s in dirs_per_conn[d]:
        s.replace('//','/')
# include implicitly named directories -> home/arne (home, home/arne)
for f in files_per_conn.keys():
    for s in files_per_conn[f]:
        splitted_s = s.split('/')
        # remove filename
        s = s[0:-(len(splitted_s[-1])+1)]
        splitted_s.pop()
        while len(s) >= 1:
            dirs_per_conn[f].append(s)
            s = s[0:-(len(splitted_s[-1])+1)]
            splitted_s.pop()
new_dirs_per_conn = {}         
for d in dirs_per_conn.keys():
    for s in dirs_per_conn[d]:
        if s[-1] == '/' and len(s)>1:
           s = s[:-1] 
        new_dirs_per_conn[d] = []
        new_dirs_per_conn[d].append(s)
        splitted_s = s.split('/')
        # remove filename
        s = s[0:-(len(splitted_s[-1])+1)]
        splitted_s.pop()
        while len(s) >= 1:
            new_dirs_per_conn[d].append(s)
            s = s[0:-(len(splitted_s[-1])+1)]
            splitted_s.pop()
dirs_per_conn = new_dirs_per_conn
set_files_per_conn = {}
set_dirs_per_conn = {}
# eliminate duplicates
for f in files_per_conn.keys():
    set_files_per_conn[f] = list(set(files_per_conn[f]))
for f in dirs_per_conn.keys():
    set_dirs_per_conn[f] = list(set(dirs_per_conn[f]))

with codecs.open(fileout,'w') as writefile:
    writefile.write(json.dumps(set_files_per_conn))
with codecs.open(dirout,'w') as writefile:
    writefile.write(json.dumps(set_dirs_per_conn))
